[
  
  {
    "title": "Snake Detection Hypothesis - Neural Net Foundations",
    "url": "/posts/Snake-Detection-Hypothesis-Neural-Net-Foundations/",
    "categories": "Machine Learning, Python, Neural Net, Computer Vision Model(s)",
    "tags": "neural-net, sdh, computer-vision",
    "date": "2024-01-15 00:00:00 -0800",
    





    
    "snippet": "Neural Net FoundationsBackgroundA study by Nagoya University on the Snake Detection Hypothesis suggests that human vision is tuned to more easily detect a potential danger, snakes. By obscuring ima...",
    "content": "Neural Net FoundationsBackgroundA study by Nagoya University on the Snake Detection Hypothesis suggests that human vision is tuned to more easily detect a potential danger, snakes. By obscuring images completely and taking incremented steps (5% correction to baseline), they were able to gauge differences in how obscured an image could remain while being identified.As I’m studying neural nets, I thought as an interesting project I could replicate the study using a computer vision (CV) model. Assuming the hypothesis is true and human vision is evolutionarily tuned to more readily detect snakes, then the correlation should not be seen when tested by a CV model. Assuming that is the result, this may suggest that features specific to snakes do not make them more easily recognizable. Snakes do have a distinctive body type when compared to most other animals, including the animals used in the study.The study used snakes, birds, cats and fish. The dataset is not publicly available, but there are fortunately plenty of publicly available models suited for the project. I have chosen ImageNet, since it is a large and well known dataset.This initial NN is based off of fastai’s imagenette, which is designed to be small and capable for quick training and evaluation at the early stages of the development process. With only 10 classes, each distinct from each other, you can get a workable and performant model.Let’s start with our imports, load our data and targets, and a few custom functions to keep things clean:from fastai.vision.all import *path = Path('/Users/ossie/sdhnet/data/animals/imagenette2-160/')lbl_dict = dict(    n01440764='tench',    n02102040='English springer',    n02979186='cassette player',    n03000684='chain saw',    n03028079='church',    n03394916='French horn',    n03417042='garbage truck',    n03425413='gas pump',    n03445777='golf ball',    n03888257='parachute',    birds='bird')def label_func(fname):  return lbl_dict[parent_label(fname)]def get_lr(learn):    lr_min, lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))    res = round( ( (lr_min + lr_steep)/2 ), 5)    print('Learning rate finder result: ', res)    return resDatablocks &amp; BatchesAs part of the development process, it is encouraged to check that everything works in each step. Let’s check a batch from our DataBlock:dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),                   get_items = get_image_files,                   get_y = label_func,                   splitter = GrandparentSplitter(),                   item_tfms = RandomResizedCrop(128, min_scale=0.35),                   batch_tfms = Normalize.from_stats(*imagenet_stats))dls = dblock.dataloaders(path, batch_size=64)dls.show_batch()Experimenting with different batch sizes, 64 is working well for the size of the dataset (700 - 900 images per category). There was some, but minimal drop in performance at smaller batch sizes of 32. Using a larger batch size can potentially increase performance by reducing training time, which is a high priority goal when producing your MVP.I’ve run into a few issues where I had a training set, but no valid set created. Let’s make sure we’ve got both in our DataLoaders:dls.train_ds(#10237) [(PILImage mode=RGB size=231x160, TensorCategory(1)),(PILImage mode=RGB size=240x160, TensorCategory(1)),(PILImage mode=RGB size=213x160, TensorCategory(1)),(PILImage mode=RGB size=228x160, TensorCategory(1)),(PILImage mode=RGB size=160x236, TensorCategory(1)),(PILImage mode=RGB size=213x160, TensorCategory(1)),(PILImage mode=RGB size=160x240, TensorCategory(1)),(PILImage mode=RGB size=213x160, TensorCategory(1)),(PILImage mode=RGB size=210x160, TensorCategory(1)),(PILImage mode=RGB size=160x236, TensorCategory(1))…]dls.valid_ds(#4117) [(PILImage mode=RGB size=213x160, TensorCategory(1)),(PILImage mode=RGB size=239x160, TensorCategory(1)),(PILImage mode=RGB size=160x200, TensorCategory(1)),(PILImage mode=RGB size=240x160, TensorCategory(1)),(PILImage mode=RGB size=240x160, TensorCategory(1)),(PILImage mode=RGB size=160x225, TensorCategory(1)),(PILImage mode=RGB size=235x160, TensorCategory(1)),(PILImage mode=RGB size=160x160, TensorCategory(1)),(PILImage mode=RGB size=160x225, TensorCategory(1)),(PILImage mode=RGB size=160x213, TensorCategory(1))…]Learners, Metrics and TrainingWith that in check, it’s time to create our learner. For the metrics, I’ve chosen accuracy, in addition to F1 Score which is a combination of ‘precision’ and ‘recall’. The F1 score should give us an understanding of how accurately positive or true predictions were correct (precision), and of all the potential positive instances, how many were identified (recall) as single, balanced, metric. By setting the average='micro', we will be able to see one score with each individual class weighed equally.We won’t be using a pre-trained model, as I’m looking to create a simple model with not too many features or attributes already trained into the network. The end goal is to compare the study with three to four CV models, with varying levels of training. Since this is the prototype and we want it quick to achieve a MVP, we can train on ResNet18. This is the smallest of the of the standard ResNet models, and should train the fastest. It should be easy to scale to a deeper network with more layers as the project progresses.It’s important to also tune the learning rate. My custom function here is leveraging fast.ai’s lr_find(), an example used here in the docs.learn = vision_learner(dls, resnet18, metrics=[accuracy, F1Score(average='micro')], pretrained=False)lr = get_lr(learn)Learning rate finder result:  0.00166Our learning rate is the midpoint between where the steepest decrease in loss occurs, and the minimum where our loss diverges and begins to increase. This should be a nice goldilocks zone that balances too low a learning rate (meaning many epochs needed to achieve a working model) and our learning rate being too large (accuracy does not reliably increase).learn.fit_one_cycle(10, lr)            epoch      train_loss      valid_loss      accuracy      f1_score      time                  0      1.423258      1.712628      0.478990      0.478990      00:39              1      1.623324      1.930002      0.407335      0.407335      00:38              2      1.597714      1.856789      0.448385      0.448385      00:38              3      1.467201      1.617843      0.532184      0.532184      00:37              4      1.352724      1.541756      0.515181      0.515181      00:38              5      1.218052      1.280943      0.580277      0.580277      00:38              6      1.048109      0.969238      0.684965      0.684965      00:38              7      0.921193      0.928279      0.698567      0.698567      00:38              8      0.832626      0.799489      0.748603      0.748603      00:37              9      0.779347      0.783034      0.746417      0.746417      00:38      interp = ClassificationInterpretation.from_learner(learn)interp.plot_confusion_matrix(figsize=(10, 10))The accuracy on predicting birds isn’t bad, but not quite matching the perfomance of the other targets.Matching the study’s dataUnfortunately, the data set used for the study is not publicly available. I wasn’t able to gather specific examples of size, source or other methods of data collection and so I chose ImageNet as a standard data source. The discrepancy in performance between target categories may be due to data set size (it’s on the lower end of our range), but it should be constructive to first bring our existing data closer to the study conditions. The Nagoya study used grayscale images, so converting the images and measuring performance again should give more insight into how well our model performs for our task.One simple change can convert our images to grayscale, using the Python Image Library (PIL) in our ImageBlock.dblock = DataBlock(blocks = (ImageBlock(cls=PILImageBW), CategoryBlock),                   get_items = get_image_files,                   get_y = label_func,                   splitter = GrandparentSplitter(),                   item_tfms = RandomResizedCrop(128, min_scale=0.35),                   batch_tfms = Normalize.from_stats(*imagenet_stats))dls = dblock.dataloaders(path, batch_size=64)dls.show_batch()learn = vision_learner(dls, resnet18, metrics=[accuracy, F1Score(average='micro')], pretrained=False)lr = get_lr(learn)learn.fit_one_cycle(10, lr)Learning rate finder result:  0.00289            epoch      train_loss      valid_loss      accuracy      f1_score      time                  0      2.667787      2.205018      0.347583      0.347583      00:37              1      2.083144      17.378586      0.137722      0.137722      00:37              2      1.813329      1.876499      0.431868      0.431868      00:37              3      1.767364      2.764703      0.254311      0.254311      00:37              4      1.703397      2.122186      0.382074      0.382074      00:37              5      1.481549      1.390573      0.549672      0.549672      00:37              6      1.329995      1.245291      0.599951      0.599951      00:38              7      1.162172      1.026676      0.678164      0.678164      00:37              8      1.014946      0.946047      0.691037      0.691037      00:37              9      0.947772      0.897824      0.710955      0.710955      00:37      bw_metrics = learn.recorder.metricsinterp = ClassificationInterpretation.from_learner(learn)interp.plot_confusion_matrix(figsize=(10, 10))Comparing the two confusion matrices, it looks like removing color resulted in a significant decrease in accuracy for the birds category, with some slight loss on others. In particular, it looks like bird more frequently gets confused with parachute. I’d guess this is because these two can be seen in the same context or setting - flying - and color features of things like the sky stand out. However, correlations with things like ‘chain saw’ and ‘birds’ are less clear, so I will be doing some feature visualization down the line to better break down what’s happening here."
  },
  
  {
    "title": "Launch &amp; Learn - My First Model",
    "url": "/posts/My-First-Model/",
    "categories": "Machine Learning, Python",
    "tags": "random-forest, kaggle",
    "date": "2023-11-06 00:00:00 -0800",
    





    
    "snippet": "Launch And Learn - My First ModelLaunchAfter months of poking around Kaggle and looking into various machine learning models, or getting lost in documentation, I finally put together my first model...",
    "content": "Launch And Learn - My First ModelLaunchAfter months of poking around Kaggle and looking into various machine learning models, or getting lost in documentation, I finally put together my first model and submission. What changed was simple: I realized worrying too much about perfection meant I never made any progress.If you haven’t heard of it, there’s a fantastic course on machine learning I’ve been working through, called fastai. An emphasis of the lessons there is a straight-forward suggestion to get something up and running so you can iterate and learn. After a few iterations I should see which levers are the most sensitive to improving (or degrading) the accuracy of my predictions.This first model ranked 3328 out of 15382 submissions, somewhere in the ballpark of the 20th percentile. Not too shabby, but I’m sure accuracy can be increased since I went for expediency rather than accuracy when prepping the training data. More on that below.Feel free to copy paste any of the below code to help yourself get started, or you can check out this repo on my GitHub.LearnWe of course start with the basic provided first cell.import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)path = '/kaggle/input/titanic'train_data = pd.read_csv(path + '/train.csv')train_data.head()Now, to get started with preparing our data we can begin feature selection. Analyzing names seems like it could potentially impact accuracy negatively, as I don’t think this data can give us a meaningful correlation (at least on this data set). The expedient thing to do was to simply drop that column.# Create feature set X, along with our test dataX = train_datatest_data = pd.read_csv(path + '/test.csv')# For the names, just dropping them for nowX = X.drop('Name', axis=1)test_data = test_data.drop('Name', axis=1)Here’s where one interesting learning experience started: RandomForestRegressor cannot handle text input - it expects only numerical input. Since the ‘Sex’ feature should have a significant impact on model accuracy, it was important to include this feature in the training.There were no numerical features to extract for this feature, however since there were only two options (gender inclusivity not being a thing in 1912) we can easily encode the data. By swapping the category with a numerical value, we can then proceed with training our model.Fortunately, this can be easily done with pandas ‘get_dummies()’ function. We can actually encode multiple features with one function call, so I included the ‘Embarked’ feature which has three potential text values of Q, C or S.# RandomForestRegressor expects numerical data, and cannot handle non-numeric categories# For sex, embarked categories, we can encode them using pandas 'get_dummies'# Which will create additional columnsX = pd.get_dummies(X, columns=['Sex', 'Embarked'])test_data = pd.get_dummies(test_data, columns=['Sex', 'Embarked'])The result of ‘get_dummies()’ above results in the addition of 5 columns in place of the original two: 2 for ‘Sex’, three for ‘Embarked’. This allows the column to specify a true/false (or 1/0) value for each category. This is a technique known as One-Hot Encoding. See Chart 1 below.# Ticket &amp; Cabin columns contain values that are difficult to encode# Dropping those columns for now, but may revisit laterX = X.drop(['Ticket', 'Cabin'], axis=1)test_data = test_data.drop(['Ticket', 'Cabin'], axis=1)# Lastly, some rows are missing the age and fare fields, dropping those columns for nowX = X.drop(['Age', 'Fare'], axis=1)test_data = test_data.drop(['Age', 'Fare'], axis=1)# test_data = test_data.dropna(subset=['Age', 'Fare'])X.head()For the features ‘Ticket’ and ‘Cabin’, we have a lot of missing values as well as data that is not suitable for one-hot encoding. While these columns are valuable as they are related to the class of the passenger, there’s a column indicating that information directly. While I imagine this results in some loss of accuracy, to get launched and iterate later, we will drop these columns.            PassengerId      Pclass      SibSp      Parch      Sex_female      Sex_male      Embarked_C      Embarked_Q      Embarked_S                  0      1      3      1      False      True      False      False      True              1      2      1      1      True      False      True      False      False              2      3      3      0      True      False      False      False      True              3      4      1      1      True      False      False      False      True              4      5      3      0      False      True      False      False      True      Chart 1: Results of One-Hot EncodingNow we can create our targets, y, and drop that column from the training set. I gave this its own cell in Kaggle to make it easier to view the head of X or y.# Create y targets from the modified X dataframey = X['Survived']# Drop the target column from X, which is already removed from test_dataX = X.drop('Survived', axis=1)X.head()Now, we can use a RandomForestClassifier and fit it to our data. Note that there is both RandomForestRegressor as well as the classifier - since we have a binary choice of survived or perished, we need to classify the passengers into a category. There are no gradients of how ‘survived’ the passenger was.# Create random forest regressorfrom sklearn.ensemble import RandomForestClassifierrf = RandomForestClassifier(n_estimators = 50, max_features = 'sqrt', max_depth = 5, random_state = 42).fit(X, y)Finally, we can leverage our model against test_data to get our predictions.# Get predictionspredictions = rf.predict(test_data)predictionsWe will need to create a DataFrame object to hold our data. For our submission, we are required to submit only the PassengerId and Survived features.submission = pd.DataFrame({    'PassengerId': test_data['PassengerId'],    'Survived': predictions})This last line will spit out a csv file we can then submit as our predictions for a ranking.submission.to_csv('submission.csv', index=False)I hope my learning process is helpful for anyone looking to get started with a basic machine learning model.Happy Hacking!"
  }
  
]

